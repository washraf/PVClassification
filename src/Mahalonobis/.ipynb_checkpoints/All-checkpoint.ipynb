{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\"><br>\n",
    "\n",
    "Importing the Necessary Libraries<br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\"><br>\n",
    "\n",
    "Creating a Pandas DataFrame from a CSV file<br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateDataFrame(types,subtype, level):\n",
    "    data = pd.read_csv('../Extraction/'+types+\"/\"+subtype+\"/\"+level+'.csv')\n",
    "    data[\"Class\"] = level\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadFullData(types,subtype):\n",
    "    if(subtype==\"All\"):\n",
    "        frames = [CreateDataFrame(types,\"Roof\",\"Clean\"), \n",
    "              CreateDataFrame(types,\"Roof\",\"Dirty (0-20)\"), \n",
    "              CreateDataFrame(types,\"Roof\",\"Dirty (20-40)\"), \n",
    "              CreateDataFrame(types,\"Roof\",\"Dirty (40-60)\"),\n",
    "              CreateDataFrame(types,\"Roof\",\"Dirty (60-80)\"),\n",
    "              CreateDataFrame(types,\"Roof\",\"Dirty (80-100)\"),\n",
    "              CreateDataFrame(types,\"Grass\",\"Clean\"), \n",
    "              CreateDataFrame(types,\"Grass\",\"Dirty (0-20)\"), \n",
    "              CreateDataFrame(types,\"Grass\",\"Dirty (20-40)\"), \n",
    "              CreateDataFrame(types,\"Grass\",\"Dirty (40-60)\"),\n",
    "              CreateDataFrame(types,\"Grass\",\"Dirty (60-80)\"),\n",
    "              CreateDataFrame(types,\"Grass\",\"Dirty (80-100)\")]\n",
    "    else:\n",
    "        frames = [CreateDataFrame(types,subtype,\"Clean\"), \n",
    "              CreateDataFrame(types,subtype,\"Dirty (0-20)\"), \n",
    "              CreateDataFrame(types,subtype,\"Dirty (20-40)\"), \n",
    "              CreateDataFrame(types,subtype,\"Dirty (40-60)\"),\n",
    "              CreateDataFrame(types,subtype,\"Dirty (60-80)\"),\n",
    "              CreateDataFrame(types,subtype,\"Dirty (80-100)\")]\n",
    "    df = pd.concat(frames)\n",
    "    #Randomize\n",
    "    df = shuffle(df)\n",
    "    y=df[['Class']].copy()\n",
    "    X = df.copy()\n",
    "    del X['Class']\n",
    "    f = df[['FileAddress']].copy()\n",
    "    del X['FileAddress']\n",
    "    X = X['Rmean','Gmean','Bmean']\n",
    "    return X,y,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadMinimizedData(types,subtype, count):\n",
    "    df = pd.read_csv('../Selection/Selection-'+types+\"-\"+subtype+\"-\"+count+\".csv\")\n",
    "    y=df[['Class']].copy()\n",
    "    X = df.copy()\n",
    "    del X['Class']\n",
    "    f = df[['FileAddress']].copy()\n",
    "    del X['FileAddress']\n",
    "    X = X['Rmean','Gmean','Bmean']\n",
    "    return X,y,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loader(types,subtype,datasize):\n",
    "    if(datasize==\"Full\"):\n",
    "        X,y,f = LoadFullData(types,subtype)\n",
    "    else:\n",
    "        count = datasize.split('-')[-1]\n",
    "        X,y,f = LoadMinimizedData(types,subtype,count)\n",
    "    return X,y,f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize KNN Classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizeKNN(X_train, y_train,cv):\n",
    "    param_grid = [{'clf__weights': [\"distance\"], 'clf__n_neighbors': [5]}]\n",
    "    clfpipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('clf', KNeighborsClassifier(algorithm='brute', \n",
    "                               metric='mahalanobis', \n",
    "                               metric_params={'V': np.cov(X_train)}))\n",
    "    ])\n",
    "    grid_search = GridSearchCV(clfpipeline, param_grid, cv=cv, verbose=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    end = time.time()\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize SVM Classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizeSVM(X_train, y_train,cv):\n",
    "    param_grid = [\n",
    "            {'clf__kernel': ['poly'],'clf__degree':[1,5],'clf__coef0':[5,10]}\n",
    "            #,{'clf__kernel': ['rbf'],'clf__gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]}\n",
    "            #,{'clf__kernel': ['sigmoid'],'clf__coef0':[1,5,10,15,20,30]}\n",
    "            #,{'clf__kernel':['linear'],'clf__C':[1,5,10]}\n",
    "            ]\n",
    "\n",
    "    clfpipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('clf', SVC())\n",
    "    ])\n",
    "    grid_search = GridSearchCV(clfpipeline, param_grid, cv=cv, verbose=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Random Forest Classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizeRandomForest(X_train, y_train,cv):\n",
    "    param_grid = [\n",
    "            {'clf__n_estimators': [30],'clf__max_features':['auto']},\n",
    "            ]\n",
    "\n",
    "    clfpipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('clf', RandomForestClassifier())])\n",
    "        \n",
    "    grid_search = GridSearchCV(clfpipeline, param_grid, cv=cv, verbose=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize NN Classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimizeNN(X_train, y_train,cv):\n",
    "    param_grid = [{'clf__hidden_layer_sizes': [(100,50,30,)]}]\n",
    "    clfpipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('clf', MLPClassifier())\n",
    "    ])\n",
    "    grid_search = GridSearchCV(clfpipeline, param_grid, cv=cv, verbose=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cycleWork(X_train, X_test, y_train, y_test,optimize,cv):\n",
    "    gridsearch = optimize(X_train, y_train,cv)\n",
    "    traintime = gridsearch.cv_results_['mean_fit_time'].mean()*1000\n",
    "    print(\"Mean Fit Time\", traintime)\n",
    "    print(\"Mean Score Time\", gridsearch.cv_results_['mean_score_time'].mean()*1000)\n",
    "\n",
    "    #print(gridsearch.best_params_)\n",
    "    estimator = gridsearch.best_estimator_\n",
    "    params = estimator.get_params()['clf']\n",
    "    print(params)\n",
    "    y_train_pred = estimator.predict(X_train)\n",
    "    trnscore = accuracy_score(y_train, y_train_pred)\n",
    "    start = time.time()\n",
    "    y_tst_pred = estimator.predict(X_test)\n",
    "    end = time.time()\n",
    "    diff = end-start\n",
    "    clfperms = X_train.shape[0]/((diff*1000)+0.000000001)\n",
    "    tstscore = accuracy_score(y_test, y_tst_pred)\n",
    "    cm = confusion_matrix(y_test, y_tst_pred)\n",
    "    true_pos = np.diag(cm) \n",
    "    precision = np.sum(true_pos / np.sum(cm, axis=0))\n",
    "    recall = np.sum(true_pos / np.sum(cm, axis=1))\n",
    "    f1 = 2 * ((precision* recall)/(precision + recall))\n",
    "    #f1None = f1_score(y_test, y_tst_pred, average=None)\n",
    "    #f1micro = f1_score(y_test, y_tst_pred, average='micro')\n",
    "    return [trnscore, tstscore, f1,traintime,clfperms,cm,params,estimator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveresultlist(types,subtype,datasize,clf,iteration,split,classifier,X,y,files):\n",
    "    data = []\n",
    "    #print(files.shape[0])\n",
    "    for i in range(0,files.shape[0]):\n",
    "        #print(files.iloc[[i]])\n",
    "        #print(X.iloc[[i]])\n",
    "        pred = classifier.predict(X.iloc[[i]])\n",
    "        #print(pred)\n",
    "        data.append([files.iloc[[i]].values[0][0],y.iloc[[i]].values[0][0],pred[0]])\n",
    "    numpyarray = np.array(data)\n",
    "    df = pd.DataFrame(numpyarray, columns = [\"File\",\"Y\",\"Pred\"])\n",
    "    fileName = \"Real-\"+types+'-'+ subtype+\"-\"+ datasize+\"-\"+ str(clf)+\"-\"+ str(iteration)+\"-\"+ str(split)+'.csv'\n",
    "    print(type(fileName))\n",
    "    df.to_csv(fileName,index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AllWork(types,subtype,sizeDict, cycles = 5, out=False,cross_validation=5):    \n",
    "    data = []\n",
    "    for datasize in sizeDict:\n",
    "        print(datasize)\n",
    "        classifiersDict = {\n",
    "                        \"KNN\":optimizeKNN,\n",
    "                        #\"SVM\":optimizeSVM,\n",
    "                        #\"RF\":optimizeRandomForest,\n",
    "                        #\"NN\":optimizeNN\n",
    "                          }\n",
    "        for clf in classifiersDict:\n",
    "            for i in range(0,cycles):\n",
    "                X,y,f = loader(types,subtype,datasize)\n",
    "                #X,y = LoadMinimizedData(types)\n",
    "                skf = StratifiedKFold(n_splits=cross_validation,shuffle = True)\n",
    "                j = 0\n",
    "                for train_index, test_index in skf.split(X, y.values.ravel()):\n",
    "                    print(\"Size \",datasize, \" Algorithm \",clf, \" Trial \",i, \" Split \", j,\" :\")\n",
    "                    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                    acc = cycleWork(X_train, X_test, y_train, y_test,classifiersDict[clf],cross_validation)\n",
    "                    #saveresultlist(types,subtype,datasize,clf,i,j,acc[7],X,y,f)\n",
    "                    print(\"Train Accuracy \",acc[0],\", Test Accuracy\",acc[1], \"F1 \",acc[2])\n",
    "                    data.append([clf,datasize.split('-')[-1],i,j,acc[0],acc[1],acc[2],acc[3],acc[4],acc[5],acc[6]])\n",
    "                    j = j+1\n",
    "                    #break\n",
    "                    print(\"########################################\")\n",
    "    numpyarray = np.array(data)\n",
    "    df = pd.DataFrame(numpyarray, columns = [\"Classifier\",\"Count\",\"Cycle\",\"Split\",\"Train Acc\", \"Test Acc\", \"F1 Score\",\"Train Time (ms)\",\"clfs per ms\",\"Confusion Matrix\",\"Params\"])\n",
    "    if(out):\n",
    "        df.to_csv(\"All-\"+types+'-'+subtype+'.csv',index = False)\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full\n",
      "Size  Full  Algorithm  KNN  Trial  0  Split  0  :\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.2min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Fit Time 37.97807693481445\n",
      "Mean Score Time 15476.899194717407\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='mahalanobis',\n",
      "           metric_params={'V': array([[379959.94429, 396156.62153, ..., 466322.49659, 302370.11606],\n",
      "       [396156.62153, 418836.26653, ..., 485060.6558 , 318227.84359],\n",
      "       ...,\n",
      "       [466322.49659, 485060.6558 , ..., 573700.86023, 371096.31053],\n",
      "       [302370.11606, 318227.84359, ..., 371096.31053, 243154.91495]])},\n",
      "           n_jobs=1, n_neighbors=5, p=2, weights='distance')\n",
      "Train Accuracy  1.0 , Test Accuracy 0.34864864864864864 F1  2.0426253379310912\n",
      "########################################\n",
      "Size  Full  Algorithm  KNN  Trial  0  Split  1  :\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.3min remaining:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Fit Time 53.75947952270508\n",
      "Mean Score Time 13321.172142028809\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='mahalanobis',\n",
      "           metric_params={'V': array([[379959.94429, 323123.18919, ..., 466322.49659, 302370.11606],\n",
      "       [323123.18919, 283146.8827 , ..., 398778.78974, 254961.24733],\n",
      "       ...,\n",
      "       [466322.49659, 398778.78974, ..., 573700.86023, 371096.31053],\n",
      "       [302370.11606, 254961.24733, ..., 371096.31053, 243154.91495]])},\n",
      "           n_jobs=1, n_neighbors=5, p=2, weights='distance')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7a15490b20c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[1;31m#\"Min-40\":40\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 }\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mAllWork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msizeDict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcycles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcycles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-9a53d44ca3bf>\u001b[0m in \u001b[0;36mAllWork\u001b[1;34m(types, subtype, sizeDict, cycles, out, cross_validation)\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcycleWork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifiersDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                     \u001b[1;31m#saveresultlist(types,subtype,datasize,clf,i,j,acc[7],X,y,f)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train Accuracy \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\", Test Accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"F1 \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-22b150e6893f>\u001b[0m in \u001b[0;36mcycleWork\u001b[1;34m(X_train, X_test, y_train, y_test, optimize, cv)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtrnscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    359\u001b[0m                 dist = pairwise_distances(\n\u001b[0;32m    360\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m                     **self.effective_metric_params_)\n\u001b[0m\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Special case to avoid picklability checks in delayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \u001b[1;31m# TODO: in some cases, backend='threading' may be appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py\u001b[0m in \u001b[0;36mcdist\u001b[1;34m(XA, XB, metric, p, V, VI, w)\u001b[0m\n\u001b[0;32m   2255\u001b[0m             \u001b[0mXB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_to_double\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2256\u001b[0m             \u001b[1;31m# sqrt((u-v)V^(-1)(u-v)^T)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2257\u001b[1;33m             \u001b[0m_distance_wrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist_mahalanobis_wrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVI\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2258\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmstr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_TEST_METRICS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "types = \"NoBG\"\n",
    "cycles = 1\n",
    "subtype = \"All\"\n",
    "sizeDict = {\n",
    "                \"Full\":None,\n",
    "                #\"Min-10\":10,\n",
    "                #\"Min-20\":20,\n",
    "                #\"Min-30\":30,\n",
    "                #\"Min-40\":40\n",
    "                }\n",
    "AllWork(types,subtype,sizeDict,cycles = cycles, out=True,cross_validation=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
