{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\"><br>\n",
    "\n",
    "Importing the Necessary Libraries<br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\"><br>\n",
    "\n",
    "Creating a Pandas DataFrame from a CSV file<br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateDataFrame(types, level):\n",
    "    data = pd.read_csv('../Extraction/'+types+\"/\"+level+'.csv')\n",
    "    data[\"Class\"] = level\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadData(types):\n",
    "    frames = [CreateDataFrame(types,\"Clean\"), \n",
    "          CreateDataFrame(types,\"Dirty (0-20)\"), \n",
    "          CreateDataFrame(types,\"Dirty (20-40)\"), \n",
    "          CreateDataFrame(types,\"Dirty (40-60)\"),\n",
    "          CreateDataFrame(types,\"Dirty (60-80)\"),\n",
    "          CreateDataFrame(types,\"Dirty (80-100)\")]\n",
    "    df = pd.concat(frames)\n",
    "    y=df[['Class']].copy()\n",
    "    X = df.copy()\n",
    "    del X['Class']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(X_train, y_train):\n",
    "    param_grid = [\n",
    "            {'svc__kernel': ['poly'],'svc__degree':[1,2,3,4,5],'svc__coef0':[1,5,10,15,20,30]},\n",
    "            {'svc__kernel': ['rbf'],'svc__gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]}\n",
    "            #,{'svc__kernel': ['sigmoid'],'svc__coef0':[1,5,10,15,20,30]}\n",
    "            ]\n",
    "\n",
    "    svcpipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('svc', SVC())\n",
    "    ])\n",
    "    grid_search = GridSearchCV(svcpipeline, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cycleWork(X_train, X_test, y_train, y_test):\n",
    "    gridsearch = optimize(X_train, y_train)\n",
    "    print(\"Mean Fit Time\", gridsearch.cv_results_['mean_fit_time'].mean()*1000)\n",
    "    print(\"Mean Score Time\", gridsearch.cv_results_['mean_score_time'].mean()*1000)\n",
    "\n",
    "    print(gridsearch.best_params_)\n",
    "    estimator = gridsearch.best_estimator_\n",
    "    \n",
    "    y_train_pred = estimator.predict(X_train)\n",
    "    trnscore = accuracy_score(y_train, y_train_pred)\n",
    "    start = time.time()\n",
    "    y_tst_pred = estimator.predict(X_test)\n",
    "    end = time.time()\n",
    "    diff = end-start\n",
    "    print(diff*1000)\n",
    "    tstscore = accuracy_score(y_test, y_tst_pred)\n",
    "    cm = confusion_matrix(y_test, y_tst_pred)\n",
    "    true_pos = np.diag(cm) \n",
    "    precision = np.sum(true_pos / np.sum(cm, axis=0))\n",
    "    recall = np.sum(true_pos / np.sum(cm, axis=1))\n",
    "    f1 = 2 * ((precision* recall)/(precision + recall))\n",
    "    #f1None = f1_score(y_test, y_tst_pred, average=None)\n",
    "    #f1micro = f1_score(y_test, y_tst_pred, average='micro')\n",
    "    return [trnscore, tstscore, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AllWork(types,cycles = 5):\n",
    "    print(types)\n",
    "    data = []\n",
    "    X,y = LoadData(types)\n",
    "    #X,y = LoadMinimizedData(types)\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle = True)\n",
    "    for train_index, test_index in skf.split(X, y.values.ravel()):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        acc = cycleWork(X_train, X_test, y_train, y_test)\n",
    "        print(\"Train Accuracy \",acc[0],\", Test Accuracy\",acc[1], \"F1 \",acc[2])\n",
    "        data.append([acc[0],acc[1],acc[2]])\n",
    "        numpyarray = np.array(data)\n",
    "        df = pd.DataFrame(numpyarray, columns = [\"Train Acc\", \"Test Acc\", \"F1 Score\"])\n",
    "        df.to_csv(\"KNN-\"+types+'.csv',index = False)\n",
    "        df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solar Data\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   37.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Fit Time 338.962893259\n",
      "Mean Score Time 48.6057951337\n",
      "{'svc__coef0': 15, 'svc__degree': 2, 'svc__kernel': 'poly'}\n",
      "31.979799270629883\n",
      "Train Accuracy  0.960431654676 , Test Accuracy 0.957142857143 F1  5.76001559681\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   40.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Fit Time 369.878742808\n",
      "Mean Score Time 52.9223476137\n",
      "{'svc__coef0': 30, 'svc__degree': 2, 'svc__kernel': 'poly'}\n",
      "35.97903251647949\n",
      "Train Accuracy  0.96585804133 , Test Accuracy 0.964157706093 F1  5.79930375409\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   40.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Fit Time 371.696681068\n",
      "Mean Score Time 51.2898354303\n",
      "{'svc__coef0': 1, 'svc__degree': 5, 'svc__kernel': 'poly'}\n",
      "25.983810424804688\n",
      "Train Accuracy  0.995507637017 , Test Accuracy 0.978494623656 F1  5.89762747037\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   40.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Fit Time 370.240362485\n",
      "Mean Score Time 52.955591111\n",
      "{'svc__coef0': 5, 'svc__degree': 5, 'svc__kernel': 'poly'}\n",
      "17.9901123046875\n",
      "Train Accuracy  1.0 , Test Accuracy 1.0 F1  6.0\n",
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 210 out of 210 | elapsed:   46.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Fit Time 432.842599778\n",
      "Mean Score Time 59.2852501642\n",
      "{'svc__coef0': 20, 'svc__degree': 2, 'svc__kernel': 'poly'}\n",
      "26.983261108398438\n",
      "Train Accuracy  0.964573991031 , Test Accuracy 0.945848375451 F1  5.69968712967\n"
     ]
    }
   ],
   "source": [
    "types = \"Solar Data\"\n",
    "AllWork(types,5)\n",
    "#types = \"NoBG\"\n",
    "#AllWork(types,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
