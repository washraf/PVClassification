{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Using NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\"><br>\n",
    "\n",
    "Importing the Necessary Libraries<br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:1.75em;color:purple; font-style:bold\"><br>\n",
    "\n",
    "Creating a Pandas DataFrame from a CSV file<br></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateDataFrame(types, level):\n",
    "    data = pd.read_csv('../Extraction/'+types+\"/\"+level+'.csv')\n",
    "    data[\"Class\"] = level\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadData(types):\n",
    "    frames = [CreateDataFrame(types,\"Clean\"), \n",
    "          CreateDataFrame(types,\"Dirty (0-20)\"), \n",
    "          CreateDataFrame(types,\"Dirty (20-40)\"), \n",
    "          CreateDataFrame(types,\"Dirty (40-60)\"),\n",
    "          CreateDataFrame(types,\"Dirty (60-80)\"),\n",
    "          CreateDataFrame(types,\"Dirty (80-100)\")]\n",
    "    df = pd.concat(frames)\n",
    "    y=df[['Class']].copy()\n",
    "    X = df.copy()\n",
    "    del X['Class']\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Classfiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(X_train, y_train):\n",
    "    param_grid = [{'clf__hidden_layer_sizes': [(100,90,80,70,60,50,40,30,20,10,),\n",
    "                                               (30,25,20,15,10,),\n",
    "                                               (30,20,10,),(20,10,)], 'clf__alpha': [0.0001,0.001]}]\n",
    "    clfpipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('clf', MLPClassifier())\n",
    "    ])\n",
    "    grid_search = GridSearchCV(clfpipeline, param_grid, cv=5, verbose=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train.values.ravel())\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cycleWork(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    gridsearch = optimize(X_train, y_train)\n",
    "    print(gridsearch.best_params_)\n",
    "    estimator = gridsearch.best_estimator_\n",
    "    \n",
    "    y_train_pred = estimator.predict(X_train)\n",
    "    trnscore = accuracy_score(y_train, y_train_pred)\n",
    "    \n",
    "    y_tst_pred = estimator.predict(X_test)\n",
    "    tstscore = accuracy_score(y_test, y_tst_pred)\n",
    "    cm = confusion_matrix(y_test, y_tst_pred)\n",
    "    true_pos = np.diag(cm) \n",
    "    precision = np.sum(true_pos / np.sum(cm, axis=0))\n",
    "    recall = np.sum(true_pos / np.sum(cm, axis=1))\n",
    "    f1 = 2 * ((precision* recall)/(precision + recall))\n",
    "    #f1None = f1_score(y_test, y_tst_pred, average=None)\n",
    "    #f1micro = f1_score(y_test, y_tst_pred, average='micro')\n",
    "    return [trnscore, tstscore, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AllWork(types,cycles = 5):\n",
    "    data = []\n",
    "    X,y = LoadData(types)\n",
    "    for i in range(0,cycles):\n",
    "        print(i)\n",
    "        acc = cycleWork(X,y)\n",
    "        print(\"Train Accuracy \",acc[0],\", Test Accuracy\",acc[1], \"F1 \",acc[2])\n",
    "        data.append([acc[0],acc[1],acc[2]])\n",
    "        numpyarray = np.array(data)\n",
    "        df = pd.DataFrame(numpyarray, columns = [\"Train Acc\", \"Test Acc\", \"F1 Score\"])\n",
    "        #df.to_csv(\"NN-\"+types+'.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.8s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   49.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__alpha': 0.001, 'clf__hidden_layer_sizes': (30, 20, 10)}\n",
      "Train Accuracy  0.980242478671 , Test Accuracy 0.97486535009 F1  5.85030183468\n",
      "0\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   32.1s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   47.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__alpha': 0.0001, 'clf__hidden_layer_sizes': (30, 20, 10)}\n",
      "Train Accuracy  0.980691513247 , Test Accuracy 0.971274685817 F1  5.81160296342\n"
     ]
    }
   ],
   "source": [
    "types = \"Solar Data\"\n",
    "AllWork(types,1)\n",
    "types = \"NoBG\"\n",
    "AllWork(types,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
